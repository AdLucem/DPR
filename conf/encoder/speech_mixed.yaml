
# @package _group_

# model type. One of [hf_bert, pytext_bert, fairseq_roberta]
encoder_model_type: mixed_hf_bert_wav2vec
#hf_bert

# HuggingFace's config name for model initialization
pretrained_model_cfg: bert-base-uncased

# Some encoders need to be initialized from a file
pretrained_file:

# Extra linear layer on top of standard bert/roberta encoder
projection_dim: 0

# Max length of the encoder input sequence
sequence_length: 256

dropout: 0.1

# whether to fix (don't update) context encoder during training or not
fix_ctx_encoder: False

# if False, the model won't load pre-trained BERT weights
pretrained: True

# HF params
pretrained_wav2vec_model_cfg:
#facebook/wav2vec2-base-960h

wav2_vec_extra_proj_dim: 768 # TODO: make a common param
wav2vec_dropout: 0.1

# fairseq params
wav2vec_cp_file: /checkpoint/vladk/speechqa/wav2vec_small.pt
# non finetuned
#wav2vec_cp_file: /checkpoint/vladk/speechqa/wav2vec_small.pt

wav2vec_apply_mask: True


# wav2vec common params
wav2vec_max_audio_t: 300
wav2vec_use_activation: False

#TODO: move to train cfg group
audio_encoder_lr_factor: 0